<div id="top-menu"></div>

<script>
  fetch("top-menu.html")
    .then(res => res.text())
    .then(data => {
      document.getElementById("top-menu").innerHTML = data;
    });
</script>

<main class="flex-grow-1">
  <div class="container py-5">

    <!-- Page Title -->
    <header class="mb-5 text-center">
      <h1 class="mb-2">Equipment</h1>
      <h5 class="text-muted">All equipment listed below has been acquired through projects undertaken by Athena Research
        Center, supporting our research and innovation activities</h5>
    </header>

    <!-- Section: UGV 4x4 -->
    <section class="mb-5" style="background-color:#f7f7f7; border-radius:6px;">
      <h3>4×4 Autonomous Ground Vehicle with Robotic Arm</h3>
      <p>
        A rugged all-terrain robotic platform equipped with a 6-DOF manipulator and rich sensor suite,
        designed for autonomous navigation, inspection, sample collection, and field robotics research
        in challenging outdoor and industrial environments.
      </p>

      <div class="row align-items-center mt-3">
        <!-- Image -->
        <div class="col-md-5 text-center mb-3 mb-md-0">
          <img src="imgs/equipment/4x4-vehicle.jpg" class="img-fluid rounded shadow-sm"
            alt="4×4 Autonomous Ground Vehicle with Robotic Arm">
        </div>

        <!-- Technical Characteristics -->
        <div class="col-md-7">
          <h5>Technical Characteristics</h5>
          <ul class="mb-3">
            <li>4×4 all-terrain mobile platform</li>
            <li>Multiple onboard cameras:
              <ul>
                <li>RGB cameras</li>
                <li>Stereo depth cameras</li>
              </ul>
            </li>
            <li>3D LiDAR sensor</li>
            <li>GPS and IMU sensors for localization and state estimation</li>
            <li>Onboard high-performance computing unit (latest generation)</li>
            <li>Remote communication and teleoperation via 5G connectivity</li>
            <li>Operating autonomy up to 5 hours</li>
            <li>Payload capacity: up to 15 kg</li>
          </ul>

          <h5>Indicative Usage Examples</h5>
          <ol class="mb-0">
            <li>
              <strong>Military / Defence:</strong>
              Surveillance, exploration, and explosive ordnance disposal (EOD),
              as well as support in high-risk operations.
            </li>
            <li>
              <strong>Security:</strong>
              Monitoring and protection of critical areas such as airports,
              ports, industrial sites, and borders.
            </li>
            <li>
              <strong>Search &amp; Rescue:</strong>
              Locating survivors in hard-to-access areas during natural or
              technological disasters.
            </li>
            <li>
              <strong>Industry:</strong>
              Load transport, infrastructure inspection, and support for
              automated production workflows in factories.
            </li>
            <li>
              <strong>Agriculture:</strong>
              Crop monitoring, fertiliser application support, and
              automated collection of field data and samples.
            </li>
          </ol>
        </div>
      </div>
    </section>

<!-- Section: Robotic Arm -->
<section class="mb-5">
  <h3>6-DOF Robotic Arm</h3>
  <p>
    The Kinova Gen2 is a lightweight and highly flexible 6-DOF robotic arm designed for applications that require
    precision, dexterity, and seamless integration. Equipped with advanced sensors and modern control technologies,
    it is ideal for industrial automation, medical robotics, human–robot interaction, and research environments.
  </p>

  <div class="row align-items-center mt-3">
    <!-- Image -->
    <div class="col-md-5 text-center mb-3 mb-md-0">
      <img src="imgs/equipment/robotic-arm.png"
           class="img-fluid rounded shadow-sm"
           alt="Kinova Gen2 Robotic Arm">
    </div>

    <!-- Technical Characteristics -->
    <div class="col-md-7">
      <h5>Key Characteristics</h5>
      <ul class="mb-3">
        <li>6 Degrees of Freedom (DOF)</li>
        <li>Lightweight design for enhanced mobility and easy deployment</li>
        <li>High precision and repeatability for fine manipulation tasks</li>
        <li>Integrated force and position sensors for responsive and safe operation</li>
        <li>Easy programming and seamless integration with robotic platforms and software</li>
        <li>Two-finger adaptive gripper for precise and stable object manipulation</li>
      </ul>

      <h5>Indicative Research-Oriented Applications</h5>
      <ol class="mb-0">
        <li>
          <strong>Industrial Automation:</strong>
          Used for automated assembly, welding, inspection, and quality control tasks.
        </li>
        <li>
          <strong>Medical Robotics & Rehabilitation:</strong>
          Supports surgical assistance, rehabilitation systems, and precise human-robot interaction workflows.
        </li>
        <li>
          <strong>Research & Development:</strong>
          Ideal for prototyping new robotic control algorithms, manipulation studies, and sensor-based automation.
        </li>
        <li>
          <strong>Autonomy & Perception:</strong>
          Integrated into autonomous platforms for accurate environmental interaction, object manipulation, 
          and advanced perception tasks.
        </li>
      </ol>
    </div>
  </div>
</section>

<!-- Section: Heavy-Duty Agricultural Spraying UAV -->
<section class="mb-5" style="background-color:#f7f7f7; border-radius:6px;">
  <h3>Heavy-Duty Spraying UAV</h3>
  <p>
    A professional-grade unmanned aerial platform designed for advanced agricultural operations.
    This high-capacity UAV supports automated spraying, fertiliser distribution, and precision
    field management, enabling efficient and targeted farming in both open fields and hard-to-reach areas.
    With RTK navigation, AI-assisted flight control, and large payload capacity, it significantly
    enhances productivity and reduces manual labour in large-scale agriculture.
  </p>

  <div class="row align-items-center mt-3">
    <!-- Image -->
    <div class="col-md-5 text-center mb-3 mb-md-0">
      <img src="imgs/equipment/drone-spray.png"
           class="img-fluid rounded shadow-sm"
           alt="Heavy-Duty Agricultural Spraying UAV">
    </div>

    <!-- Technical Characteristics -->
    <div class="col-md-7">
      <h5>Technical Characteristics</h5>
      <ul class="mb-3">
        <li>Payload capacity: up to 40 kg</li>
        <li>30L spraying tank for liquid applications</li>
        <li>Precision RTK positioning system</li>
        <li>AI-based flight management and obstacle detection</li>
        <li>16 high-precision spray nozzles</li>
        <li>Spray output: 8 L/min</li>
        <li>Coverage capacity: up to 160 acres/hour</li>
        <li>Dual FPV cameras for front and downward vision</li>
        <li>40L granular spreader attachment</li>
      </ul>

      <h5>Indicative Usage Examples</h5>
      <ol class="mb-0">
        <li>
          <strong>Crop Spraying:</strong>
          Automated application of pesticides with high accuracy,
          reducing chemical waste and improving crop coverage.
        </li>
        <li>
          <strong>Fertiliser Distribution:</strong>
          Efficient spreading of granular or liquid fertilisers
          for improved nutrient management.
        </li>
        <li>
          <strong>Access to Hard-to-Reach Areas:</strong>
          Enables safe and automated operation in terrains or zones
          that cannot be accessed easily by farm workers or ground equipment.
        </li>
      </ol>
    </div>
  </div>
</section>

<!-- Section: Multispectral Imaging UAV -->
<section class="mb-5">
  <h3>Multispectral Imaging UAV</h3>
  <p>
    A high-precision unmanned aerial vehicle equipped with RGB and multispectral sensors,
    designed for data-driven agriculture, vegetation monitoring, and advanced environmental analytics.
    With centimetre-level accuracy and real-time visualisation, this UAV supports professionals in
    precision farming, environmental assessment, archaeology, and scientific research.
  </p>

  <div class="row align-items-center mt-3">
    <!-- Image -->
    <div class="col-md-5 text-center mb-3 mb-md-0">
      <img src="imgs/equipment/drone-multispectral.png"
           class="img-fluid rounded shadow-sm"
           alt="Multispectral Imaging UAV">
    </div>

    <!-- Technical Characteristics -->
    <div class="col-md-7">
      <h5>Technical Characteristics</h5>
      <ul class="mb-3">
        <li>RGB camera for high-resolution visual mapping</li>
        <li>Integrated multispectral camera for vegetation and crop analysis</li>
        <li>Centimetre-level positioning accuracy</li>
        <li>D-RTK 2 Mobile Station support</li>
        <li>Real-time analytics and result presentation during flights</li>
      </ul>

      <h5>Indicative Usage Examples</h5>
      <ol class="mb-0">

        <!-- Agriculture & Farm Management -->
        <li>
          <strong>Agricultural Monitoring (NDVI):</strong>
          Generation of NDVI and vegetation index maps to identify plant stress,
          optimise crop management, and detect health anomalies.
        </li>
        <li>
          <strong>Resource Optimisation:</strong>
          Enables efficient management of water, fertilisers, and soil nutrients,
          reducing costs and environmental impact.
        </li>
        <li>
          <strong>Pest & Disease Detection:</strong>
          Early identification of crop diseases and infestations for rapid response actions.
        </li>

        <!-- Other domains -->
        <li>
          <strong>Environmental Monitoring:</strong>
          Forest health assessment, early fire detection, and tracking deforestation.
        </li>
        <li>
          <strong>Soil & Geological Surveys:</strong>
          Analysis of soil composition and detection of geological formations for scientific studies.
        </li>
        <li>
          <strong>Archaeology & Cultural Heritage:</strong>
          Detection of buried archaeological structures and monitoring of monuments
          and cultural sites through multispectral anomalies.
        </li>
      </ol>
    </div>
  </div>
</section>

<!-- Section: Thermal Imaging UAV -->
<section class="mb-5" style="background-color:#f7f7f7; border-radius:6px;">
  <h3>Thermal Imaging UAV</h3>
  <p>
    A compact and highly capable unmanned aerial vehicle equipped with a high-resolution thermal sensor,
    designed for heat detection, inspection, and real-time situational awareness. This UAV supports a wide
    range of missions including emergency response, industrial inspection, border security, and urban safety,
    offering reliable performance in day and night operations.
  </p>

  <div class="row align-items-center mt-3">
    <!-- Image -->
    <div class="col-md-5 text-center mb-3 mb-md-0">
      <img src="imgs/equipment/drone-thermal.png"
           class="img-fluid rounded shadow-sm"
           alt="Thermal Imaging UAV">
    </div>

    <!-- Technical Characteristics -->
    <div class="col-md-7">
      <h5>Technical Characteristics</h5>
      <ul class="mb-3">
        <li>High-resolution thermal imaging camera for heat detection and thermal mapping</li>
        <li>High-quality optical RGB camera for visual inspections</li>
        <li>Extended flight endurance for long-duration missions</li>
        <li>Autonomous flight modes including predefined routes and automatic return-to-home</li>
      </ul>

      <h5>Indicative Usage Examples</h5>
      <ol class="mb-0">
        <li>
          <strong>Thermal Loss Detection:</strong>
          Identification of heat leakage in buildings, insulation issues, and cooling system anomalies.
        </li>
        <li>
          <strong>Fire Detection & Monitoring:</strong>
          Early fire spotting, wildfire monitoring, and assessment of fire progression from a safe distance.
        </li>
        <li>
          <strong>Search & Rescue:</strong>
          Locating missing persons or vehicles in hard-to-access or low-visibility environments.
        </li>
        <li>
          <strong>Border Surveillance:</strong>
          Detection and monitoring of unauthorized crossings in rural or remote areas.
        </li>
        <li>
          <strong>Urban Security & Safety:</strong>
          Monitoring public events, detecting security breaches, and supporting law-enforcement operations.
        </li>
        <li>
          <strong>Operational Infrastructure Monitoring:</strong>
          Inspecting industrial facilities, energy fields, and critical infrastructure for thermal anomalies.
        </li>
      </ol>
    </div>
  </div>
</section>
<!-- Section: Multi-Drone Aerial Swarm -->
<section class="mb-5">
  <h3>Multi-Drone Aerial Swarm</h3>
  <p>
    A coordinated swarm of lightweight unmanned aerial vehicles designed for multi-agent missions,
    aerial mapping, environmental monitoring, and research experiments. This drone swarm offers high
    flexibility, portability, and collective autonomous capabilities, enabling advanced aerial sensing,
    3D reconstruction, and large-scale data acquisition across a wide range of scientific and operational domains.
  </p>

  <div class="row align-items-center mt-3">
    <!-- Image -->
    <div class="col-md-5 text-center mb-3 mb-md-0">
      <img src="imgs/equipment/drone-swarm.png"
           class="img-fluid rounded shadow-sm"
           alt="Multi-Drone Aerial Swarm">
    </div>

    <!-- Technical Characteristics -->
    <div class="col-md-7">
      <h5>Technical Characteristics</h5>
      <ul class="mb-3">
        <li>Highly portable and lightweight UAV units for easy deployment</li>
        <li>High-resolution cameras for aerial photography and video</li>
        <li>Autonomous and coordinated swarm flight capabilities</li>
        <li>Extended flight endurance enabling long-duration missions</li>
      </ul>

      <h5>Indicative Usage Examples</h5>
      <ol class="mb-0">
        <li>
          <strong>Aerial Photography & Videography:</strong>
          Capturing high-quality images and videos from multiple angles for creative,
          documentary, and operational purposes.
        </li>
        <li>
          <strong>Environmental Monitoring:</strong>
          Tracking changes in vegetation, wildlife, deforestation, air and water quality,
          and other ecological indicators.
        </li>
        <li>
          <strong>Geospatial Applications:</strong>
          Generating digital maps, terrain models, and monitoring land-use changes through
          synchronized multi-angle imaging.
        </li>
        <li>
          <strong>Archaeological Surveys:</strong>
          Inspecting archaeological sites from the air, enabling rapid documentation and
          assisting excavation processes.
        </li>
        <li>
          <strong>Scientific Research:</strong>
          Supporting studies related to climate change, disaster assessment, ecosystem
          analysis, and biodiversity monitoring.
        </li>
        <li>
          <strong>Mapping & 3D Reconstruction:</strong>
          Acquiring synchronized images for creating detailed 3D models and topographic maps
          using multi-drone perspectives.
        </li>
      </ol>
    </div>
  </div>
</section>

<!-- Section: Small-Scale Ground Robot Swarm -->
<section class="mb-5" style="background-color:#f7f7f7; border-radius:6px;">
  <h3>Small-Scale Ground Robot Swarm</h3>
  <p>
    A fleet of compact autonomous ground vehicles designed for multi-agent research,
    AI experimentation, and real-world simulation of autonomous navigation.
    These small-scale robotic units enable rapid prototyping, testing, and evaluation
    of advanced algorithms in artificial intelligence, robotics control, perception,
    and autonomous mobility.
  </p>

  <div class="row align-items-center mt-3">
    <!-- Image -->
    <div class="col-md-5 text-center mb-3 mb-md-0">
      <img src="imgs/equipment/drone-smal-cars.png"
           class="img-fluid rounded shadow-sm"
           alt="Small-Scale Ground Robot Swarm">
    </div>

    <!-- Technical Characteristics -->
    <div class="col-md-7">
      <h5>Technical Characteristics</h5>
      <ul class="mb-3">
        <li>
          Mobile robotic platform based on an RC vehicle chassis, equipped with modular
          mounting options for sensors and controllers.
        </li>
        <li>
          Autonomous control system powered by machine learning algorithms and AI-based
          decision-making modules.
        </li>
        <li>
          Integrated sensors including RGB cameras, stereo cameras, distance sensors, LiDAR, gyroscopes,
          and accelerometers for perception and navigation.
        </li>
        <li>
          High-performance computing support for training and deploying machine learning
          models such as neural networks and reinforcement learning policies.
        </li>
      </ul>

      <h5>Indicative Usage Examples</h5>
      <ol class="mb-0">
        <li>
          <strong>Artificial Intelligence Research:</strong>
          Training and testing AI/ML algorithms such as neural networks and reinforcement learning
          for autonomous driving tasks.
        </li>
        <li>
          <strong>Robotics Control & Automation:</strong>
          Development and evaluation of autonomous vehicle control strategies for accuracy,
          responsiveness, and real-time decision-making.
        </li>
        <li>
          <strong>Computer Vision & Object Detection:</strong>
          Experimentation with perception algorithms for obstacle recognition, tracking,
          and scene understanding.
        </li>
        <li>
          <strong>Environmental Monitoring:</strong>
          Useful for monitoring agricultural fields, forest areas, borders, and fire-prone zones.
        </li>
        <li>
          <strong>Agricultural Research:</strong>
          Crop monitoring, plant health assessment, detection of diseases, and productivity analysis
          using small-scale autonomous platforms.
        </li>
      </ol>
    </div>
  </div>
</section>

<!-- Section: Embedded AI Computing Boards -->
<section class="mb-5">
  <h3>Embedded AI Computing Boards</h3>
  <p>
    Compact, high-performance computing units designed for computer vision, artificial intelligence,
    robotics, and real-time data processing. These systems serve as flexible platforms for research,
    education, prototyping, and deployment of intelligent applications in diverse environments such as
    industry, IoT ecosystems, smart systems, and autonomous robotics.
  </p>

  <div class="row align-items-center mt-3">
    <!-- Image -->
    <div class="col-md-5 text-center mb-3 mb-md-0">
      <img src="imgs/equipment/edge-computing.png"
           class="img-fluid rounded shadow-sm"
           alt="Embedded AI Computing Boards">
    </div>

    <!-- Technical Characteristics -->
    <div class="col-md-7">
      <h5>Technical Characteristics</h5>
      <ul class="mb-3">
        <li>High computational performance suitable for AI/ML workloads</li>
        <li>Built-in internet connectivity for cloud and IoT integration</li>
        <li>
          Support for a wide range of sensors including cameras, distance sensors,
          temperature sensors, and motion detectors
        </li>
      </ul>

      <h5>Indicative Usage Examples</h5>
      <ol class="mb-0">
        <li>
          <strong>Educational Experiments:</strong>
          Ideal for hands-on learning in schools, universities, and robotics workshops.
        </li>
        <li>
          <strong>IoT Development:</strong>
          Programming and integrating with Internet-of-Things platforms for smart systems and automation.
        </li>
        <li>
          <strong>AI-Driven Applications:</strong>
          Deployment of deep learning models for video analysis, face recognition,
          autonomous driving prototypes, and real-time perception.
        </li>
        <li>
          <strong>Robotics & Automation:</strong>
          Designing high-precision robotic systems and intelligent automation workflows.
        </li>
        <li>
          <strong>Large-Scale Systems:</strong>
          Supporting industrial, medical, and operational environments that require
          reliable onboard computation.
        </li>
      </ol>
    </div>
  </div>
</section>



    <!-- Section: HPC -->
    <section class="mb-5">
      <h3>High-Performance Computing Server</h3>
      <p>
        A multi-GPU server featuring 10× NVIDIA RTX A6000 GPUs and 1 TB RAM—
        supporting large-scale deep reinforcement learning, digital twins, image processing,
        and scientific simulations.
      </p>

      <div class="text-center my-3">
        <img src="imgs/equipment/placeholder.png" class="img-fluid rounded shadow-sm" alt="HPC Server">
      </div>
    </section>

    <!-- Section: Cameras -->
    <section class="mb-5">
      <h3>Specialised Cameras</h3>
      <p>
        Our lab includes depth, thermal, multispectral, and LiDAR-enabled cameras
        used for SLAM, 3D reconstruction, thermal inspection, crop diagnostics,
        XR interaction, and robotics navigation.
      </p>

      <div class="text-center my-3">
        <img src="imgs/equipment/placeholder.png" class="img-fluid rounded shadow-sm" alt="Cameras">
      </div>
    </section>

    <!-- Section: XR Headsets -->
    <section class="mb-5">
      <h3>Extended Reality (XR) Headsets</h3>
      <p>
        Our XR suite includes HoloLens 2, Magic Leap One, and Oculus Quest 2—
        supporting immersive training, museum experiences, digital twins,
        teleoperation, and collaborative mixed-reality design.
      </p>

      <div class="text-center my-3">
        <img src="imgs/equipment/placeholder.png" class="img-fluid rounded shadow-sm" alt="XR Headsets">
      </div>
    </section>

    <!-- Section: Motion Sensors -->
    <section class="mb-5">
      <h3>Motion Tracking Sensors</h3>
      <p>
        Including Leap Motion controllers for hand tracking and interaction,
        used in XR, robotics teleoperation, and gesture-based interfaces.
      </p>

      <div class="text-center my-3">
        <img src="imgs/equipment/placeholder.png" class="img-fluid rounded shadow-sm" alt="Motion Sensors">
      </div>
    </section>

  </div>
</main>

<div id="footer"></div>
<script>
  fetch("footer.html")
    .then(res => res.text())
    .then(data => {
      document.getElementById("footer").innerHTML = data;
    });
</script>

<script src="./js/bootstrap.bundle.min.js"></script>